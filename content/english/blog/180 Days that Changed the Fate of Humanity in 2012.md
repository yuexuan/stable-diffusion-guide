---
title: 180 Days that Changed the Fate of Humanity in 2012
date: 2023-11-15
tags:
  - AI Art Create
  - Stable Diffusion Guide
  - Artificial Intelligence
  - Deep Learning
  - Technology History
  - Computer Vision
  - ImageNet Challenge
excludeSearch: false
---
One day in early December 2012, a secret auction was taking place in a casino hotel at Lake Tahoe, a skiing haven in the United States.

Straddling the border between California and Nevada, Lake Tahoe is North America's largest alpine lake, known for its sapphire waters and top-tier ski slopes. It has been a filming location for "The Godfather Part II" and a favorite retreat for Mark Twain. Due to its proximity to the San Francisco Bay Area, about 200 miles away, it is often referred to as "Silicon Valley's backyard." Tech moguls like Mark Zuckerberg and Larry Ellison have staked claims here, building luxurious estates.

The object of the secret auction was DNNresearch, a company barely a month old with just three employees, founded by University of Toronto professor Geoffrey Hinton and two of his students.

This company had no tangible products or assets, yet the identity of its pursuers hinted at its significance—**the four bidders were Google, Microsoft, DeepMind, and Baidu.**

![](https://img.36krcdn.com/hsossms/20230907/v2_04deed7c3d12490881beb6ee2021e0bc@000000_oswg49029oswg702oswg352_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
*The auction was held in Harrah's Hotel at Lake Tahoe in 2012.*

Geoffrey Hinton, 65 years old, thin, and suffering from chronic back pain, sat on the floor of room 703 in the hotel, setting the rules for the auction—starting at $12 million, with increments of at least $1 million.

After several hours, the bid had skyrocketed to $44 million. Hinton, feeling somewhat dizzy, thought, "It's like we're in a movie," and decided to halt the auction, selling the company to the last bidder—Google.

Interestingly, the auction's genesis was an initiative from Google six months earlier.

In June 2012, Google's research department, Google Brain, publicly unveiled the findings of The Cat Neurons project, which essentially identified cats in YouTube videos. Initiated by Andrew Ng, who had moved from Stanford to Google, and including Google's legendary Jeff Dean, the project received substantial funding from Google co-founder Larry Page.

The Google Cat project built a neural network that downloaded numerous videos from YouTube, unmarked, allowing the model to observe and learn the characteristics of cats on its own. It then employed 16,000 CPUs from Google’s data centers for training (internally rejected using GPUs due to complexity and cost), achieving a recognition accuracy of 74.8%. This figure stunned the industry.

As the "Google Cat" project was nearing completion, Ng made a bold move to focus on his internet education project. Before leaving, he recommended Hinton as his replacement. Hinton, open to a temporary stint at Google but unwilling to leave academia, ended up as Google's oldest summer intern at 64.

Hinton had been at the forefront of artificial intelligence since the 1980s, a professor with numerous successful students, including Ng. He was a master in the field of deep learning. After delving into the technical details of the "Google Cat" project, he quickly identified its hidden flaws: "They ran the wrong neural network and used the wrong computational power."

Believing he could do better, Hinton sprung into action after his brief "internship."

He enlisted two of his students, Ilya Sutskever and Alex Krizhevsky, both born in the Soviet Union and of Jewish descent, with the former having a gift for mathematics and the latter skilled in engineering. Together, they created a new neural network and immediately entered the ImageNet image recognition competition (ILSVRC), astonishingly winning with an 84% accuracy rate.

In October 2012, Hinton's team introduced their winning algorithm, AlexNet, at a computer vision conference in Florence. Unlike the Google Cat project, which used 16,000 CPUs, AlexNet only needed four NVIDIA GPUs. The academic and industrial worlds were thoroughly shaken. The AlexNet paper became one of the most influential in the history of computer science, now cited over 120,000 times, while the Google Cat project was quickly forgotten.
![](https://img.36krcdn.com/hsossms/20230907/v2_311edd3c25174e6bb35973b901b5f42f@000000_oswg51051oswg1064oswg798_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
*The DNNresearch team, winners of the first ImageNet competition.*

Yukai, a deep learning expert born in Jiangxi, who had just moved from NEC to Baidu, read the paper and was electrified. He immediately emailed Hinton to propose collaboration. Hinton agreed and decided to package himself and his two students into a company, inviting buyers to bid, leading to the scene described at the beginning.

After the auction concluded, a greater race began: Google, riding on its victory, acquired DeepMind in 2014, bringing "all heroes under its banner." DeepMind then shocked the world with AlphaGo in 2016. Baidu, having lost to Google, resolved to bet on AI, investing billions over a decade. Yukai later brought in Andrew Ng to Baidu before leaving to start Horizon Robotics.

Microsoft, seemingly a step behind, eventually secured the biggest prize—OpenAI, co-founded by one of Hinton's students, Ilya Sutskever. Hinton himself stayed at Google until 2023, receiving the ACM Turing Award. Of course, compared to Google's $44 million (of which Hinton received 40%), the Turing Award's $1 million prize seemed like pocket change.

From the Google Cat project in June to the AlexNet paper in October, and the Lake Tahoe auction in December, nearly six months laid the groundwork for the AI wave—deep learning's prosperity, GPU and NVIDIA's rise, AlphaGo's dominance, the birth of Transformer, and the emergence of ChatGPT... A grand symphony of the silicon age played its first note.

The 180 days from June to December 2012 forever changed the fate of carbon-based humanity—only a few realized it at the time.

## **Liquid Cats**

Among those few was Stanford University professor Fei-Fei Li.

In 2012, when Hinton's participation in the ImageNet competition results were announced, Li, just having had a child and on maternity leave, realized history was being rewritten. As the founder of the ImageNet challenge, she caught the last flight to Florence to personally award Hinton's team.

Born in Beijing and raised in Chengdu, Li moved to the United States with her parents at 16, helping in a laundry while completing her education at Princeton. In 2009, she joined Stanford as an assistant professor, focusing on computer vision and machine learning. This field aims to enable computers to understand images and videos like humans.

For instance, when a camera captures a cat, it merely converts light into pixels, unaware whether the subject is a cat or a dog. If we compare the camera to human eyes, computer vision is about adding a brain to the camera.

The traditional approach is to abstract real-world objects into mathematical models, like simplifying a cat's features into basic geometric shapes, significantly reducing the difficulty of machine recognition.

![](https://img.36krcdn.com/hsossms/20230907/v2_4159e5e886d64014ba89ae9ddf5c2f8b@000000_oswg209873oswg1080oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

But this approach has its limitations because a cat might look like this:
![](https://img.36krcdn.com/hsossms/20230907/v2_3967050d5974487a9c4ff8cad01721a9@000000_oswg768286oswg1000oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

To recognize "liquid cats," pioneers in deep learning like Geoff Hinton and Yann LeCun have been exploring since the 1980s. However, they always hit bottlenecks in computing power or algorithms—good algorithms lacked sufficient computing power, and those requiring less power couldn't meet recognition accuracy, making industrialization unfeasible.

If the "liquid cat" problem remained unsolved, the allure of deep learning would be confined to theory, and industrial applications like autonomous driving, medical imaging, and precision ad targeting would remain pipe dreams.

Simply put, the development of deep learning requires three pillars: **algorithm, computing power, and data**. The **algorithm** dictates how computers recognize objects, but it needs ample **computing power**; meanwhile, algorithmic improvement requires large-scale, high-quality **data**. These three elements are interdependent.

Post-2000, while the bottleneck of computing power gradually eased with advancements in chip processing capabilities, the mainstream academic community remained lukewarm about deep learning. Li realized that the bottleneck might not be in the precision of the algorithms themselves but in the lack of high-quality, large-scale datasets.

Li's inspiration came from how three-year-old children recognize the world. Taking cats as an example, a child repeatedly encounters cats under the guidance of adults, gradually understanding what a cat is. If a child's eyes are like a camera, each movement of the eyeball equals a shutter click, meaning a three-year-old has already taken hundreds of millions of photos.

Applying this to computers, if we continuously show them images of cats and other animals, annotating the correct answer for each, the computer, by repeatedly checking against the answers, might grasp the concept of a cat given enough repetitions.

The only problem was: **Where to find so many annotated images?**
![](https://img.36krcdn.com/hsossms/20230907/v2_9e4c394877d846a2adf30bb494eac534@000000_oswg521472oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

This was the genesis of ImageNet. Back then, even the largest dataset, PASCAL, only had four categories with a total of 1,578 images. Li aimed to create a dataset with hundreds of categories and tens of millions of images. While this seems feasible now, it was a monumental task in 2006, when the world's most popular phone was still the Nokia 5300.

Using Amazon's crowdsourcing platform, Li's team tackled the massive workload of manual annotation. In 2009, the ImageNet dataset with 3.2 million images was born. With this image dataset, algorithms could be trained to improve recognition capabilities. However, compared to a three-year-old's hundreds of millions of images, 3.2 million was still a drop in the bucket.

To facilitate the expansion of its dataset, Li Fei-Fei decided to follow a popular industry practice by organizing an image recognition contest. Participants would use their algorithms to recognize images from the dataset, with the highest accuracy winning. However, the deep learning approach was not mainstream at the time, and ImageNet initially had to "attach" itself to the well-known European contest PASCAL to barely gather enough participants.

By 2012, the number of images in ImageNet had expanded to include 15 million images across 1,000 categories, a feat Li Fei-Fei accomplished in six years, effectively addressing the data shortfall. However, the best performance in the ILSVRC still had an error rate of 25%, showing that in terms of algorithms and computing power, there was still not enough convincing power.

At this juncture, Professor Geoff Hinton entered the scene with AlexNet and two GTX580 graphics cards.

## **CNN**

Hinton's team's championship algorithm, AlexNet, adopted a method known as Convolutional Neural Networks (CNN). "Neural network" is a highly frequent term in the field of artificial intelligence and a branch of machine learning, named and structured after the operation of the human brain.

The process of human object recognition involves the pupil first capturing pixels, with the cerebral cortex initially processing edges and orientation, followed by the brain abstracting to make determinations. Thus, the human brain can identify objects based on certain features.

For instance, without showing the entire face, most people can recognize the person in the image below:

![](https://img.36krcdn.com/hsossms/20230907/v2_5a32088bbbad4ddeafcc1de40bf400ba@000000_oswg390000oswg1064oswg384_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

Neural networks essentially simulate the human brain's recognition mechanism, theoretically enabling computers to perform intelligence tasks that the human brain can. Compared to methods like SVM, decision trees, and random forests, only by simulating the human brain can unstructured data like "liquid cats" and "half a Trump" be processed.

The challenge is that the human brain has about 100 billion neurons, and the synapses between them number in the trillions, forming an incredibly complex network. In contrast, the "Google Cat," assembled with 16,000 CPUs, had a total of 1 billion nodes, already the most complex computer system of its time.

This is why even "the father of artificial intelligence" Marvin Minsky was skeptical of this approach. In his 2007 book "The Emotion Machine," Minsky still expressed pessimism about neural networks. To change the mainstream machine learning community's long-term negative attitude towards artificial neural networks, Hinton simply renamed it to deep learning (Deep Learning).

In 2006, Hinton published a paper in Science introducing the concept of "Deep Belief Neural Networks (DBNN)" and presented a training method for multi-layer deep neural networks, considered a major breakthrough in deep learning. However, Hinton's method required massive computational power and data, making practical application difficult.

Deep learning continuously requires feeding data to the algorithm. The data sets available at the time were too small, until the arrival of ImageNet.

In the first two competitions of ImageNet, participating teams used other machine learning approaches, and the results were quite mediocre. In contrast, Hinton's team used the convolutional neural network AlexNet in 2012, an improvement on another deep learning pioneer Yann LeCun's 1998 LeNet, which allowed the algorithm to extract key features of images, like Trump's blond hair.

Additionally, the convolutional kernel slides over the input image, ensuring the detection of the same features regardless of the object's position, greatly reducing computational requirements.

AlexNet, building upon the classic convolutional neural network structure, abandoned the previous layer-by-layer unsupervised approach, applying supervised learning to the input values, significantly improving accuracy.

For example, in the image in the lower right corner below, AlexNet did not correctly identify the subject (a Madagascar cat), but its list included other small mammals that climb trees like the Madagascar cat, indicating that the algorithm can not only recognize the object itself but also make inferences based on other objects.

![](https://img.36krcdn.com/hsossms/20230907/v2_7e7ee391ed7c423ab24356bf27611e75@000000_oswg1069456oswg980oswg798_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

The industrial sector was invigorated by the fact that AlexNet had 60 million parameters and 650,000 neurons, requiring at least 2.62 trillion floating-point operations to fully train the ImageNet dataset. However, Hinton's team used only two NVIDIA GTX 580 graphics cards during a week-long training process.

## **GPU**

After Hinton's team won the championship, Google, embarrassingly, lagged behind.

It's said that Google also conducted internal tests on the ImageNet dataset, but their recognition accuracy was far behind Hinton's team. Considering Google's unmatched hardware resources, as well as the massive data scale of its search and YouTube services, and the special attention given to Google Brain, their results were not convincing enough.

Without such a stark contrast, deep learning might not have shocked the industry and gained recognition and popularity in such a short time. The excitement in the industry was due to the fact that Hinton's team achieved such impressive results with just four GPUs, suggesting that computational power was no longer a bottleneck.

During the training of algorithms, each layer of the neural network is computed to produce output results, and GPUs have strong parallel computing capabilities. In a 2009 paper, Andrew Ng had already demonstrated this, but when running the "Google Cat" project with Jeff Dean, they still used CPUs. Later, Jeff Dean specifically ordered $2 million worth of equipment, still excluding GPUs.

Hinton was one of the few who realized the immense value of GPUs for deep learning early on. However, before AlexNet made its mark, high-tech companies generally had an ambiguous attitude toward GPUs.

In 2009, Hinton was invited to Microsoft for a short-term technical consulting project on a speech recognition project. He suggested to the project leader, Li Deng, to buy the top-of-the-line NVIDIA GPUs, along with the corresponding servers. Li Deng supported this idea, but his superior, Alex Acero, thought it was a waste of money, saying, "GPUs are for playing games, not for artificial intelligence research."
![Li Deng](https://img.36krcdn.com/hsossms/20230907/v2_f4540ef49eac40b2b1b61d040119cd68@000000_oswg720798oswg1040oswg632_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
*Li Deng*

Interestingly, Alex Acero later joined Apple, responsible for Apple's voice recognition software Siri.

Microsoft's ambivalence towards GPUs clearly frustrated Hinton. He later suggested in an email to Li Deng to buy a set of equipment, while he himself would buy three sets, sarcastically noting: "After all, we are a well-funded Canadian university, not a cash-strapped software vendor."

But after the 2012 ImageNet Challenge, all AI scholars and tech companies made a 180-degree turn in their attitude towards GPUs. In 2014, Google's GoogLeNet won with a 93% recognition accuracy using NVIDIA GPUs. That year, the number of GPUs used by all participating teams soared to 110.

This edition of the challenge is considered a "big bang moment" because it filled the gaps in the three driving forces of deep learning—algorithm, computing power, and data—making industrialization just a matter of time.

![](https://img.36krcdn.com/hsossms/20230907/v2_e72f9968790b485995e3c698d2dac29b@000000_oswg83414oswg1080oswg863_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

Algorithmically, the paper on AlexNet published by Hinton's team became one of the most cited in the field of computer science. Deep learning became the dominant technology, with nearly all computer vision research turning towards neural networks.

In terms of computing power, GPUs' strong parallel computing capabilities and adaptability to deep learning were rapidly recognized by the industry. NVIDIA, which began laying the groundwork for CUDA six years earlier, emerged as the biggest winner.

Data-wise, ImageNet became the touchstone for image processing algorithms. With high-quality datasets, the accuracy of algorithms improved by leaps and bounds. In the last challenge held in 2017, the winning algorithm achieved a recognition accuracy of 97.3%, surpassing human performance.

At the end of October 2012, Hinton's student Alex Krizhevsky presented the paper at a computer vision conference in Florence, Italy. Then, high-tech companies around the world began two things without regard to cost: buying up all of NVIDIA's graphics cards and poaching AI researchers from universities.

The $44 million from Lake Tahoe re-priced the global deep learning gurus.

## **Capture the Flag**

From publicly available information, it's true that Kai Yu from Baidu was the first to approach Hinton.

At the time, Yu was the head of Baidu's Multimedia Department, the precursor to Baidu's Deep Learning Research Institute (IDL). After receiving Yu's email, Hinton quickly replied agreeing to cooperate, also expressing his hope for some funding from Baidu. When Yu asked for a specific amount, Hinton indicated $1 million would be enough—a number so low it was unbelievable, only affording two P8s.

Yu consulted with Robin Li, who readily agreed. After Yu replied with no problem, Hinton sensed the industry's thirst and asked if Yu would mind if he approached others, like Google. Yu later recalled:

"I regretted it a bit at the time, guessing I might have answered too quickly, making Hinton realize the great opportunity. But all I could do was graciously say I didn't mind."

Eventually, Baidu missed out on collaborating with Hinton's team. But for this outcome, Yu was not unprepared. On the one hand, Hinton had severe lumbar disc health problems, couldn't drive or fly, and would find it difficult to endure the trip across the Pacific to China; on the other hand, Hinton had too many students and friends working at Google, and the other three companies were essentially just making up the numbers.

If AlexNet's impact was still mainly in academic circles, then the secret auction at Lake Tahoe completely shocked the industrial world—because under the noses of global tech companies, Google spent $44 million on a company less than a month old, with no products, no revenue, just three employees and a few papers.

Despite losing an auction, Baidu's management was profoundly influenced by Google's unhesitant investment in deep learning. This led to the establishment of Baidu's Institute of Deep Learning (IDL) in January 2013. In May 2014, Baidu hired Andrew Ng, a key figure in Google's "Google Cat" project, followed by the recruitment of Qi Lu, a former Microsoft executive, in January 2017.

**Google's Continued Efforts and Acquisition of DeepMind**

After acquiring the Hinton team, Google persistently advanced, acquiring its former auction rival DeepMind for $600 million in 2014. Elon Musk, who had invested in DeepMind, recommended the company to Google's founder Larry Page. To facilitate a visit to London with Hinton, Google even chartered a private plane with modified seating to accommodate Hinton's inability to fly.

**DeepMind's Go Victory and Facebook's Move**
![](https://img.36krcdn.com/hsossms/20230907/v2_559119b170134c648ebf5f51ec07549a@000000_oswg508066oswg810oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
DeepMind, referred to as the "British contestant," triumphed over Lee Sedol in Go in 2016. Facebook, having lost DeepMind to Google, turned to Yann LeCun, one of the "three giants of deep learning." To secure LeCun, Mark Zuckerberg agreed to several stringent demands, such as establishing the AI lab in New York, maintaining a clear boundary between the lab and product teams, and allowing LeCun to retain his position at New York University.

**The Talent Mismatch Post-2012 ImageNet Challenge**

The rapid expansion of industries like recommendation algorithms, image recognition, and autonomous driving led to an explosive demand for talent. However, deep learning researchers were scarce, leading to a severe talent mismatch. Tech companies, desperate for expertise, began acquiring "talent futures" by hiring professors and waiting for their students to follow.

LeCun's move to Facebook was followed by six of his students. Apple, eager to enter the automotive space, hired Hinton's student Ruslan Salakhutdinov as its first AI director. Even hedge fund Citadel joined the talent war, recruiting Deng Li, who had worked with Hinton on voice recognition and represented Microsoft in the secret auction.

**The AI Boom: Face Recognition, Machine Translation, Autonomous Driving**
![](https://img.36krcdn.com/hsossms/20230907/v2_bfb4730122f54d8b93c47bfd43ae4493@000000_oswg256527oswg1080oswg722_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

![](https://img.36krcdn.com/hsossms/20230907/v2_5ec6612f09a84522a7c577301f83aef0@000000_oswg163432oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)

![](https://img.36krcdn.com/hsossms/20230907/v2_82f0037e831346d89026fe2b499089fe@000000_oswg177816oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
Following these developments, industries like face recognition, machine translation, and autonomous driving advanced rapidly. GPU orders surged towards NVIDIA's headquarters in Santa Clara. The theoretical foundations of AI were being rapidly built.

In 2017, Google introduced the Transformer model in the paper "Attention is all you need," marking the beginning of the era of large models. A few years later, ChatGPT emerged.

**The Genesis of AI: The 2012 ImageNet Challenge**

The birth of this AI era can be traced back to the 2012 ImageNet Challenge.

So, in which year did the historical process that led to the "Big Bang moment" of 2012 become evident?

The answer is 2006.

## **Greatness**

Before 2006, the state of deep learning could be summarized with a famous quote from Lord Kelvin: the edifice of deep learning was essentially built, but there were three small dark clouds floating under the bright sunshine.

These three dark clouds were algorithms, computing power, and data.

As mentioned earlier, deep learning, by simulating the mechanisms of the human brain, is a theoretically perfect solution. However, the challenge lay in the scale of data it required and the computing power it consumed, both of which were of a science-fiction level at that time. The mainstream academic view on deep learning was: **only a scholar with an unsound mind would study neural networks.**

But three events in 2006 changed this:

**Hinton and his student Salakhutdinov published a paper in Science titled 'Reducing the Dimensionality of Data with Neural Networks', proposing for the first time an effective solution to the vanishing gradient problem, marking a significant step forward in algorithm development.**

![](https://img.36krcdn.com/hsossms/20230907/v2_3f0b6939dad244178dd303221bae01de@000000_oswg964087oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
*Salakhutdinov (first from left) and Hinton (center), 2016*

**Fei-Fei Li of Stanford University realized that if the scale of data was insufficient to replicate the complexity of the real world, even the best algorithms would struggle to achieve 'brain-like' performance through training. Therefore, she began constructing the ImageNet dataset.**

**NVIDIA released a new GPU architecture, Tesla, and introduced the CUDA platform, significantly lowering the difficulty for developers to train deep neural networks using GPUs, cutting down the daunting barrier of computing power.**

The occurrence of these three events dissipated the dark clouds over deep learning, converging at the 2012 ImageNet challenge, completely altering the destiny of the high-tech industry and human society as a whole.

However, in 2006, whether it was Geoff Hinton, Fei-Fei Li, Jen-Hsun Huang, or others driving the development of deep learning, it was impossible for them to foresee the subsequent boom in artificial intelligence, let alone the roles they would play.

![](https://img.36krcdn.com/hsossms/20230907/v2_a91bc26c62c34086ba8b0795bb6a7c34@000000_oswg487744oswg1080oswg652_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
*Hinton and Salakhutdinov's paper*

Today, the Fourth Industrial Revolution, driven by AI, has begun, and the evolution of artificial intelligence will only accelerate. The lessons we can learn may be summarized as follows:

**1. The depth of an industry determines the height of innovation.**

When ChatGPT emerged, the question "Why is it always the US?" was frequently asked. But if we look at the longer timeline, from transistors and integrated circuits to Unix and the x86 architecture, and now machine learning, the American academic and industrial sectors have almost always been the leaders.

This is because, despite ongoing discussions about the 'hollowing out' of American industry, the computer science industry, centered around software, has not only never 'flowed out' to other economies but has grown increasingly dominant. To this day, nearly all of the more than 70 ACM Turing Award winners are Americans.

The reason why Andrew Ng chose to collaborate with Google on the 'Google Cat' project was largely because only Google had the data and computing power required for algorithm training, which in turn was built on Google's strong profitability. This is the advantage of industry depth — talent, investment, and innovation capability all gravitate towards the high ground of the industry.

China, in its own advantageous industries, also demonstrates this 'depth advantage'. The most typical example is the new energy vehicle sector, where European car companies charter planes to Chinese car expos to learn from new forces, while Japanese auto executives frequently jump ship to BYD — obviously, they're after more than just social security benefits in Shenzhen.

**2. The more cutting-edge the technological field, the more important talent becomes.**

Google's willingness to spend $44 million to acquire Hinton's company was because in a cutting-edge field like deep learning, the impact of a top scholar often exceeds that of ten thousand fresh graduates in computer vision. If Baidu or Microsoft had won the bid at that time, the trajectory of AI development might have been rewritten.

This kind of 'buy the whole company for you' behavior is actually very common. During the key phase of Apple's self-developed chips, the casual acquisition of a small company, PASemi, was to get chip architecture guru Jim Keller on board — Apple's A4, AMD's Zen, and Tesla's FSD chip all benefited from Jim Keller's technical support.

This is the biggest advantage brought by industry competitiveness — the attraction of talent.

None of the 'three giants of deep learning' are American. The name AlexNet comes from Hinton's student, Alex Krizhevsky, who was born in Ukraine under Soviet rule, grew up in Israel, and came to Canada for study. Not to mention the many Chinese faces still active in American high-tech companies today.

**3. The difficulty of innovation lies in facing uncertainty.**

Aside from 'father of AI' Marvin Minsky, another well-known opponent of deep learning was Jitendra Malik from UC Berkeley, who has ridiculed both Hinton and Andrew Ng. Fei-Fei Li also consulted Malik when building ImageNet, and his advice to her was: Do something more useful.

![](https://img.36krcdn.com/hsossms/20230907/v2_7824d396b06443248ef652175db3ebe1@000000_oswg306394oswg1080oswg619_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
Fei-Fei Li's TED Talk

It was this skepticism from industry pioneers that led to decades of silence in deep learning. Even by 2006, when Hinton tore through a ray of light, another of the three giants, Yann LeCun, was still repeatedly proving the value of deep learning to the academic community.

LeCun had been studying neural networks since the 1980s and, during his time at Bell Labs, he and his colleagues designed a chip called ANNA to solve the computing power issue. Later, when AT&T, under operational pressure, required its research department to 'enable business', LeCun's response was 'I just want to study computer vision, fire me if you dare'. He eventually got his wish, receiving a severance package.

Every researcher in a cutting-edge technology field must face one question: **What if this doesn't work out?**

Counting from 1972 when he entered the University of Edinburgh, Hinton had been battling on the front lines of deep learning for 50 years. At the time of the 2012 ImageNet challenge, he was already 65 years old. It's hard to imagine how much self-doubt and negation he had to overcome during those long years in the face of academic skepticism.

Today we know that Hinton in 2006 had already persevered through the darkest hours before dawn, but he himself might not have known this, let alone the entire academic and industrial world. Just like the reaction of most people to the iPhone's release in 2007, which was probably similar to that of then-Microsoft CEO Steve Ballmer:

![](https://img.36krcdn.com/hsossms/20230907/v2_dd863c61057842459937f1de1239d94d@000000_oswg1016138oswg1080oswg1286_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1)
The iPhone is still the world's most expensive phone, and it has no keyboard

Those who drive history often cannot guess their coordinates in the historical process.

Greatness is not defined by its stunning emergence, but by enduring the long periods of obscurity and misunderstanding in endless darkness. Only years later can people trace these milestones and marvel at the brilliance and abundance of talent at that time.

In one scientific field after another, countless scholars spend their lives without ever glimpsing a ray of hope. In this sense, Hinton and other promoters of deep learning are fortunate. They have created greatness and indirectly driven one success after another in the industry.

The capital market assigns a fair price to success, but history records the loneliness and sweat of those who create greatness.

(This post is reposted from 36Kr, solely for the purpose of explaining the impact of 2012 on AI, [Original post](https://36kr.com/p/2421889040802823))